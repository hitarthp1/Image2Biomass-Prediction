{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0040fe1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T08:43:58.464716Z",
     "iopub.status.busy": "2025-12-28T08:43:58.464481Z",
     "iopub.status.idle": "2025-12-28T09:46:35.440720Z",
     "shell.execute_reply": "2025-12-28T09:46:35.439668Z"
    },
    "papermill": {
     "duration": 3756.981494,
     "end_time": "2025-12-28T09:46:35.442680",
     "exception": false,
     "start_time": "2025-12-28T08:43:58.461186",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Train rows: 357\n",
      "\n",
      "================================================================================\n",
      "Training convnext_base | img=512 | lr=0.0003\n",
      "[init] loaded: convnext_base_pretrained.safetensors | missing=4 unexpected=0\n",
      "convnext_base | fold 0 | ep 000/20 | tr=88.8082 va=61.8446 wR2=-0.3130 lr=3.00e-04 r2=[-0.201, -0.036, -0.083, -0.320, -0.434]\n",
      "convnext_base | fold 0 | ep 001/20 | tr=63.8634 va=58.2325 wR2=-0.1555 lr=3.00e-04 r2=[-0.029, -0.126, -0.037, -0.150, -0.213]\n",
      "convnext_base | fold 0 | ep 002/20 | tr=60.7742 va=53.5647 wR2=-0.0090 lr=3.00e-04 r2=[0.072, -0.118, -0.014, 0.032, -0.019]\n",
      "convnext_base | fold 0 | ep 003/20 | tr=58.9980 va=51.3563 wR2=0.0433 lr=3.00e-04 r2=[0.107, 0.100, 0.012, 0.123, -0.006]\n",
      "convnext_base | fold 0 | ep 004/20 | tr=54.0013 va=47.0044 wR2=0.2116 lr=3.00e-04 r2=[0.162, 0.200, 0.085, 0.279, 0.222]\n",
      "convnext_base | fold 0 | ep 005/20 | tr=52.4135 va=44.5260 wR2=0.2915 lr=3.00e-04 r2=[0.263, 0.229, 0.176, 0.323, 0.320]\n",
      "convnext_base | fold 0 | ep 006/20 | tr=50.1436 va=43.1924 wR2=0.3125 lr=3.00e-04 r2=[0.290, 0.213, 0.163, 0.393, 0.335]\n",
      "convnext_base | fold 0 | ep 007/20 | tr=45.5657 va=40.0222 wR2=0.3919 lr=3.00e-04 r2=[0.370, 0.373, 0.267, 0.423, 0.413]\n",
      "convnext_base | fold 0 | ep 008/20 | tr=42.8832 va=38.5485 wR2=0.4401 lr=3.00e-04 r2=[0.413, 0.404, 0.313, 0.481, 0.462]\n",
      "convnext_base | fold 0 | ep 009/20 | tr=39.9251 va=35.9663 wR2=0.4685 lr=3.00e-04 r2=[0.470, 0.527, 0.332, 0.479, 0.480]\n",
      "convnext_base | fold 0 | ep 010/20 | tr=41.6331 va=37.7799 wR2=0.4438 lr=3.00e-04 r2=[0.470, 0.392, 0.220, 0.509, 0.468]\n",
      "convnext_base | fold 0 | ep 011/20 | tr=39.7256 va=36.6638 wR2=0.5081 lr=3.00e-04 r2=[0.458, 0.425, 0.222, 0.562, 0.570]\n",
      "convnext_base | fold 0 | ep 012/20 | tr=35.4983 va=35.4324 wR2=0.5427 lr=3.00e-04 r2=[0.511, 0.497, 0.358, 0.594, 0.575]\n",
      "convnext_base | fold 0 | ep 013/20 | tr=33.6096 va=34.9427 wR2=0.5589 lr=3.00e-04 r2=[0.502, 0.464, 0.362, 0.622, 0.604]\n",
      "convnext_base | fold 0 | ep 014/20 | tr=31.0470 va=35.1783 wR2=0.5475 lr=3.00e-04 r2=[0.472, 0.354, 0.380, 0.618, 0.606]\n",
      "convnext_base | fold 0 | ep 015/20 | tr=29.8750 va=34.0124 wR2=0.5505 lr=3.00e-04 r2=[0.554, 0.500, 0.406, 0.597, 0.570]\n",
      "convnext_base | fold 0 | ep 016/20 | tr=30.3468 va=32.4989 wR2=0.5986 lr=3.00e-04 r2=[0.588, 0.488, 0.430, 0.641, 0.640]\n",
      "convnext_base | fold 0 | ep 017/20 | tr=29.6878 va=33.2798 wR2=0.5996 lr=3.00e-04 r2=[0.561, 0.588, 0.401, 0.641, 0.633]\n",
      "convnext_base | fold 0 | ep 018/20 | tr=28.0487 va=35.3299 wR2=0.5102 lr=3.00e-04 r2=[0.548, 0.385, 0.442, 0.565, 0.520]\n",
      "convnext_base | fold 0 | ep 019/20 | tr=28.5132 va=30.7988 wR2=0.6506 lr=3.00e-04 r2=[0.671, 0.644, 0.430, 0.698, 0.673]\n",
      "Done convnext_base fold 0 | best wR2=0.6506\n",
      "[init] loaded: convnext_base_pretrained.safetensors | missing=4 unexpected=0\n",
      "convnext_base | fold 1 | ep 000/20 | tr=86.6326 va=67.2720 wR2=-0.3020 lr=3.00e-04 r2=[-0.158, -0.062, -0.035, -0.323, -0.424]\n",
      "convnext_base | fold 1 | ep 001/20 | tr=61.1611 va=63.3132 wR2=-0.1316 lr=3.00e-04 r2=[-0.052, -0.030, 0.023, -0.144, -0.194]\n",
      "convnext_base | fold 1 | ep 002/20 | tr=61.3295 va=62.9041 wR2=-0.1085 lr=3.00e-04 r2=[-0.034, -0.011, 0.024, -0.125, -0.163]\n",
      "convnext_base | fold 1 | ep 003/20 | tr=53.0850 va=57.6509 wR2=0.0391 lr=3.00e-04 r2=[0.050, 0.085, 0.123, 0.028, 0.015]\n",
      "convnext_base | fold 1 | ep 004/20 | tr=48.8532 va=57.5633 wR2=0.1118 lr=3.00e-04 r2=[0.098, 0.189, 0.179, 0.088, 0.095]\n",
      "convnext_base | fold 1 | ep 005/20 | tr=46.0193 va=53.6333 wR2=0.1139 lr=3.00e-04 r2=[0.122, 0.282, 0.174, 0.043, 0.095]\n",
      "convnext_base | fold 1 | ep 006/20 | tr=45.6705 va=54.1596 wR2=0.1691 lr=3.00e-04 r2=[0.165, 0.310, 0.254, 0.108, 0.149]\n",
      "convnext_base | fold 1 | ep 007/20 | tr=42.8397 va=50.6003 wR2=0.2425 lr=3.00e-04 r2=[0.203, 0.380, 0.330, 0.190, 0.226]\n",
      "convnext_base | fold 1 | ep 008/20 | tr=41.2737 va=49.1760 wR2=0.2374 lr=3.00e-04 r2=[0.230, 0.426, 0.352, 0.164, 0.207]\n",
      "convnext_base | fold 1 | ep 009/20 | tr=38.6024 va=49.6031 wR2=0.2942 lr=3.00e-04 r2=[0.266, 0.433, 0.336, 0.238, 0.286]\n",
      "convnext_base | fold 1 | ep 010/20 | tr=35.7386 va=44.6870 wR2=0.3635 lr=3.00e-04 r2=[0.314, 0.491, 0.387, 0.306, 0.366]\n",
      "convnext_base | fold 1 | ep 011/20 | tr=34.3850 va=45.8880 wR2=0.3845 lr=3.00e-04 r2=[0.343, 0.338, 0.338, 0.389, 0.410]\n",
      "convnext_base | fold 1 | ep 012/20 | tr=33.7318 va=41.9561 wR2=0.4198 lr=3.00e-04 r2=[0.378, 0.510, 0.401, 0.382, 0.429]\n",
      "convnext_base | fold 1 | ep 013/20 | tr=31.0592 va=41.6449 wR2=0.4078 lr=3.00e-04 r2=[0.396, 0.586, 0.386, 0.337, 0.407]\n",
      "convnext_base | fold 1 | ep 014/20 | tr=29.6241 va=42.2099 wR2=0.4010 lr=3.00e-04 r2=[0.403, 0.633, 0.434, 0.354, 0.366]\n",
      "convnext_base | fold 1 | ep 015/20 | tr=29.3176 va=40.7245 wR2=0.4890 lr=3.00e-04 r2=[0.450, 0.599, 0.401, 0.435, 0.514]\n",
      "convnext_base | fold 1 | ep 016/20 | tr=27.0567 va=38.1878 wR2=0.5149 lr=3.00e-04 r2=[0.495, 0.578, 0.352, 0.538, 0.530]\n",
      "convnext_base | fold 1 | ep 017/20 | tr=28.1942 va=38.6246 wR2=0.4975 lr=3.00e-04 r2=[0.461, 0.630, 0.394, 0.481, 0.505]\n",
      "convnext_base | fold 1 | ep 018/20 | tr=25.6667 va=37.6274 wR2=0.4880 lr=3.00e-04 r2=[0.507, 0.621, 0.394, 0.498, 0.473]\n",
      "convnext_base | fold 1 | ep 019/20 | tr=23.9011 va=39.2714 wR2=0.4994 lr=1.50e-04 r2=[0.453, 0.607, 0.348, 0.445, 0.539]\n",
      "Done convnext_base fold 1 | best wR2=0.5149\n",
      "[init] loaded: convnext_base_pretrained.safetensors | missing=4 unexpected=0\n",
      "convnext_base | fold 2 | ep 000/20 | tr=81.0992 va=69.4488 wR2=-0.2125 lr=3.00e-04 r2=[-0.283, 0.004, -0.054, -0.248, -0.259]\n",
      "convnext_base | fold 2 | ep 001/20 | tr=60.6829 va=66.2412 wR2=-0.1588 lr=3.00e-04 r2=[-0.140, -0.002, -0.058, -0.180, -0.206]\n",
      "convnext_base | fold 2 | ep 002/20 | tr=58.9262 va=62.4656 wR2=-0.0720 lr=3.00e-04 r2=[-0.071, 0.036, -0.016, -0.086, -0.100]\n",
      "convnext_base | fold 2 | ep 003/20 | tr=55.3311 va=63.3856 wR2=0.0481 lr=3.00e-04 r2=[-0.021, 0.038, 0.041, 0.061, 0.060]\n",
      "convnext_base | fold 2 | ep 004/20 | tr=55.0311 va=58.6350 wR2=0.1538 lr=3.00e-04 r2=[0.076, 0.079, 0.103, 0.176, 0.186]\n",
      "convnext_base | fold 2 | ep 005/20 | tr=52.7338 va=55.9991 wR2=0.1245 lr=3.00e-04 r2=[0.088, 0.168, 0.055, 0.179, 0.115]\n",
      "convnext_base | fold 2 | ep 006/20 | tr=50.2455 va=53.7175 wR2=0.2233 lr=3.00e-04 r2=[0.194, 0.153, 0.103, 0.229, 0.265]\n",
      "convnext_base | fold 2 | ep 007/20 | tr=47.0560 va=50.7811 wR2=0.1910 lr=3.00e-04 r2=[0.203, 0.226, 0.183, 0.159, 0.196]\n",
      "convnext_base | fold 2 | ep 008/20 | tr=43.9926 va=45.0726 wR2=0.3691 lr=3.00e-04 r2=[0.345, 0.250, 0.210, 0.422, 0.409]\n",
      "convnext_base | fold 2 | ep 009/20 | tr=40.1354 va=44.3862 wR2=0.4046 lr=3.00e-04 r2=[0.389, 0.276, 0.198, 0.471, 0.448]\n",
      "convnext_base | fold 2 | ep 010/20 | tr=41.1842 va=45.8967 wR2=0.3347 lr=3.00e-04 r2=[0.350, 0.310, 0.211, 0.299, 0.376]\n",
      "convnext_base | fold 2 | ep 011/20 | tr=39.6173 va=42.1692 wR2=0.4122 lr=3.00e-04 r2=[0.454, 0.397, 0.128, 0.494, 0.431]\n",
      "convnext_base | fold 2 | ep 012/20 | tr=36.0736 va=40.0895 wR2=0.4913 lr=3.00e-04 r2=[0.481, 0.428, 0.237, 0.551, 0.533]\n",
      "convnext_base | fold 2 | ep 013/20 | tr=34.7618 va=38.4644 wR2=0.5455 lr=3.00e-04 r2=[0.534, 0.363, 0.220, 0.664, 0.602]\n",
      "convnext_base | fold 2 | ep 014/20 | tr=32.4926 va=37.5919 wR2=0.5591 lr=3.00e-04 r2=[0.586, 0.406, 0.204, 0.685, 0.605]\n",
      "convnext_base | fold 2 | ep 015/20 | tr=31.2658 va=34.3237 wR2=0.5887 lr=3.00e-04 r2=[0.642, 0.424, 0.245, 0.719, 0.627]\n",
      "convnext_base | fold 2 | ep 016/20 | tr=30.6363 va=42.2228 wR2=0.5336 lr=3.00e-04 r2=[0.593, 0.297, 0.103, 0.721, 0.580]\n",
      "convnext_base | fold 2 | ep 017/20 | tr=31.9492 va=42.0795 wR2=0.5288 lr=3.00e-04 r2=[0.606, 0.335, 0.080, 0.700, 0.573]\n",
      "convnext_base | fold 2 | ep 018/20 | tr=29.9429 va=35.2898 wR2=0.5379 lr=1.50e-04 r2=[0.642, 0.423, 0.220, 0.632, 0.566]\n",
      "convnext_base | fold 2 | ep 019/20 | tr=27.0814 va=34.7308 wR2=0.6305 lr=1.50e-04 r2=[0.653, 0.509, 0.251, 0.737, 0.684]\n",
      "Done convnext_base fold 2 | best wR2=0.6305\n",
      "[init] loaded: convnext_base_pretrained.safetensors | missing=4 unexpected=0\n",
      "convnext_base | fold 3 | ep 000/20 | tr=84.4781 va=59.3161 wR2=-0.2388 lr=3.00e-04 r2=[-0.208, -0.013, -0.055, -0.285, -0.309]\n",
      "convnext_base | fold 3 | ep 001/20 | tr=63.2147 va=56.3732 wR2=-0.1487 lr=3.00e-04 r2=[-0.081, -0.069, -0.002, -0.175, -0.197]\n",
      "convnext_base | fold 3 | ep 002/20 | tr=59.4784 va=54.5359 wR2=0.0115 lr=3.00e-04 r2=[-0.017, 0.060, 0.070, 0.027, -0.010]\n",
      "convnext_base | fold 3 | ep 003/20 | tr=58.6292 va=50.8244 wR2=0.0399 lr=3.00e-04 r2=[0.084, 0.123, 0.112, 0.100, -0.024]\n",
      "convnext_base | fold 3 | ep 004/20 | tr=52.1595 va=48.5411 wR2=0.1041 lr=3.00e-04 r2=[0.160, 0.049, 0.209, 0.122, 0.076]\n",
      "convnext_base | fold 3 | ep 005/20 | tr=47.9369 va=46.5147 wR2=0.2524 lr=3.00e-04 r2=[0.219, 0.303, 0.211, 0.293, 0.241]\n",
      "convnext_base | fold 3 | ep 006/20 | tr=46.9436 va=45.1952 wR2=0.2323 lr=3.00e-04 r2=[0.261, 0.305, 0.281, 0.251, 0.195]\n",
      "convnext_base | fold 3 | ep 007/20 | tr=43.2788 va=41.6702 wR2=0.2997 lr=3.00e-04 r2=[0.342, 0.379, 0.252, 0.375, 0.255]\n",
      "convnext_base | fold 3 | ep 008/20 | tr=40.5227 va=39.7819 wR2=0.4249 lr=3.00e-04 r2=[0.369, 0.422, 0.333, 0.479, 0.433]\n",
      "convnext_base | fold 3 | ep 009/20 | tr=39.0850 va=37.9883 wR2=0.4411 lr=3.00e-04 r2=[0.426, 0.470, 0.314, 0.493, 0.443]\n",
      "convnext_base | fold 3 | ep 010/20 | tr=36.3308 va=36.0607 wR2=0.4783 lr=3.00e-04 r2=[0.473, 0.476, 0.381, 0.558, 0.467]\n",
      "convnext_base | fold 3 | ep 011/20 | tr=34.1280 va=37.2290 wR2=0.4571 lr=3.00e-04 r2=[0.488, 0.481, 0.379, 0.550, 0.425]\n",
      "convnext_base | fold 3 | ep 012/20 | tr=34.6365 va=35.5993 wR2=0.4814 lr=3.00e-04 r2=[0.513, 0.579, 0.372, 0.541, 0.454]\n",
      "convnext_base | fold 3 | ep 013/20 | tr=33.1959 va=36.4039 wR2=0.4484 lr=3.00e-04 r2=[0.464, 0.596, 0.457, 0.470, 0.405]\n",
      "convnext_base | fold 3 | ep 014/20 | tr=31.6040 va=32.9592 wR2=0.5338 lr=3.00e-04 r2=[0.557, 0.596, 0.410, 0.619, 0.507]\n",
      "convnext_base | fold 3 | ep 015/20 | tr=28.4808 va=32.8807 wR2=0.5899 lr=3.00e-04 r2=[0.601, 0.551, 0.479, 0.667, 0.587]\n",
      "convnext_base | fold 3 | ep 016/20 | tr=26.3877 va=31.4916 wR2=0.6010 lr=3.00e-04 r2=[0.626, 0.582, 0.464, 0.692, 0.591]\n",
      "convnext_base | fold 3 | ep 017/20 | tr=24.9999 va=35.8395 wR2=0.5118 lr=3.00e-04 r2=[0.571, 0.469, 0.209, 0.664, 0.508]\n",
      "convnext_base | fold 3 | ep 018/20 | tr=25.9724 va=34.6798 wR2=0.5113 lr=3.00e-04 r2=[0.556, 0.579, 0.369, 0.589, 0.486]\n",
      "convnext_base | fold 3 | ep 019/20 | tr=24.8087 va=32.8988 wR2=0.5556 lr=1.50e-04 r2=[0.599, 0.625, 0.440, 0.614, 0.533]\n",
      "Done convnext_base fold 3 | best wR2=0.6010\n",
      "[init] loaded: convnext_base_pretrained.safetensors | missing=4 unexpected=0\n",
      "convnext_base | fold 4 | ep 000/20 | tr=83.5254 va=61.8771 wR2=-0.2136 lr=3.00e-04 r2=[-0.187, 0.016, -0.130, -0.166, -0.301]\n",
      "convnext_base | fold 4 | ep 001/20 | tr=61.8016 va=55.2898 wR2=-0.0413 lr=3.00e-04 r2=[-0.044, 0.083, 0.007, -0.016, -0.085]\n",
      "convnext_base | fold 4 | ep 002/20 | tr=56.5938 va=54.0419 wR2=0.0423 lr=3.00e-04 r2=[0.004, -0.052, -0.042, 0.142, 0.046]\n",
      "convnext_base | fold 4 | ep 003/20 | tr=53.1289 va=49.9694 wR2=0.0911 lr=3.00e-04 r2=[0.074, 0.076, 0.049, 0.176, 0.072]\n",
      "convnext_base | fold 4 | ep 004/20 | tr=48.0267 va=47.7117 wR2=0.1846 lr=3.00e-04 r2=[0.162, 0.129, 0.123, 0.245, 0.188]\n",
      "convnext_base | fold 4 | ep 005/20 | tr=44.6724 va=44.6273 wR2=0.2566 lr=3.00e-04 r2=[0.209, 0.269, 0.250, 0.267, 0.261]\n",
      "convnext_base | fold 4 | ep 006/20 | tr=41.2026 va=42.1760 wR2=0.3293 lr=3.00e-04 r2=[0.254, 0.300, 0.364, 0.323, 0.346]\n",
      "convnext_base | fold 4 | ep 007/20 | tr=40.5877 va=40.2840 wR2=0.3629 lr=3.00e-04 r2=[0.286, 0.273, 0.376, 0.378, 0.387]\n",
      "convnext_base | fold 4 | ep 008/20 | tr=38.5152 va=41.6039 wR2=0.3747 lr=3.00e-04 r2=[0.317, 0.174, 0.379, 0.435, 0.402]\n",
      "convnext_base | fold 4 | ep 009/20 | tr=35.7299 va=41.2511 wR2=0.3893 lr=3.00e-04 r2=[0.366, 0.265, 0.421, 0.406, 0.406]\n",
      "convnext_base | fold 4 | ep 010/20 | tr=32.4155 va=36.8493 wR2=0.4781 lr=3.00e-04 r2=[0.401, 0.278, 0.473, 0.523, 0.516]\n",
      "convnext_base | fold 4 | ep 011/20 | tr=31.7651 va=39.0655 wR2=0.4583 lr=3.00e-04 r2=[0.415, 0.279, 0.406, 0.517, 0.490]\n",
      "convnext_base | fold 4 | ep 012/20 | tr=30.5314 va=37.7040 wR2=0.4244 lr=3.00e-04 r2=[0.430, 0.410, 0.399, 0.464, 0.416]\n",
      "convnext_base | fold 4 | ep 013/20 | tr=27.5839 va=34.1230 wR2=0.5207 lr=3.00e-04 r2=[0.470, 0.384, 0.497, 0.537, 0.556]\n",
      "convnext_base | fold 4 | ep 014/20 | tr=26.5132 va=34.9939 wR2=0.4476 lr=3.00e-04 r2=[0.484, 0.447, 0.435, 0.479, 0.430]\n",
      "convnext_base | fold 4 | ep 015/20 | tr=24.9313 va=31.8989 wR2=0.5532 lr=3.00e-04 r2=[0.531, 0.422, 0.538, 0.572, 0.579]\n",
      "convnext_base | fold 4 | ep 016/20 | tr=25.0054 va=35.6932 wR2=0.4544 lr=3.00e-04 r2=[0.474, 0.419, 0.503, 0.459, 0.446]\n",
      "convnext_base | fold 4 | ep 017/20 | tr=23.8955 va=32.3873 wR2=0.5273 lr=3.00e-04 r2=[0.544, 0.414, 0.483, 0.578, 0.535]\n",
      "convnext_base | fold 4 | ep 018/20 | tr=22.0285 va=30.6712 wR2=0.5794 lr=3.00e-04 r2=[0.564, 0.478, 0.622, 0.581, 0.593]\n",
      "convnext_base | fold 4 | ep 019/20 | tr=21.1372 va=34.1470 wR2=0.5634 lr=3.00e-04 r2=[0.569, 0.413, 0.536, 0.600, 0.583]\n",
      "Done convnext_base fold 4 | best wR2=0.5794\n",
      "convnext_base CV avg: 0.595284390449524\n",
      "\n",
      "================================================================================\n",
      "Training effnetv2_s | img=512 | lr=0.001\n",
      "[init] loaded: tf_efficientnetv2_s_pretrained.safetensors | missing=2 unexpected=0\n",
      "effnetv2_s | fold 0 | ep 000/20 | tr=86.5829 va=62.3509 wR2=-0.0491 lr=1.00e-03 r2=[0.279, 0.125, -1.105, 0.388, -0.113]\n",
      "effnetv2_s | fold 0 | ep 001/20 | tr=53.2949 va=49.5738 wR2=0.2043 lr=1.00e-03 r2=[0.489, -0.091, -0.210, 0.332, 0.238]\n",
      "effnetv2_s | fold 0 | ep 002/20 | tr=45.6877 va=52.9708 wR2=-0.1264 lr=1.00e-03 r2=[-0.284, 0.321, 0.269, -0.224, -0.224]\n",
      "effnetv2_s | fold 0 | ep 003/20 | tr=42.4445 va=40.3908 wR2=0.4153 lr=1.00e-03 r2=[0.681, 0.468, 0.244, 0.458, 0.369]\n",
      "effnetv2_s | fold 0 | ep 004/20 | tr=43.8433 va=51.7367 wR2=0.3067 lr=1.00e-03 r2=[0.054, 0.323, -0.137, 0.232, 0.472]\n",
      "effnetv2_s | fold 0 | ep 005/20 | tr=37.3947 va=34.7042 wR2=0.5259 lr=1.00e-03 r2=[0.683, 0.550, 0.324, 0.606, 0.498]\n",
      "effnetv2_s | fold 0 | ep 006/20 | tr=33.4744 va=38.7430 wR2=0.4264 lr=1.00e-03 r2=[0.692, 0.569, 0.164, 0.609, 0.324]\n",
      "effnetv2_s | fold 0 | ep 007/20 | tr=35.5844 va=37.8759 wR2=0.5121 lr=1.00e-03 r2=[0.502, 0.577, 0.190, 0.544, 0.553]\n",
      "effnetv2_s | fold 0 | ep 008/20 | tr=34.7403 va=35.7557 wR2=0.5536 lr=1.00e-03 r2=[0.637, 0.610, 0.362, 0.661, 0.521]\n",
      "effnetv2_s | fold 0 | ep 009/20 | tr=32.9480 va=32.5328 wR2=0.6236 lr=1.00e-03 r2=[0.720, 0.735, 0.228, 0.752, 0.610]\n",
      "effnetv2_s | fold 0 | ep 010/20 | tr=32.4143 va=34.8487 wR2=0.5767 lr=1.00e-03 r2=[0.689, 0.589, 0.354, 0.669, 0.560]\n",
      "effnetv2_s | fold 0 | ep 011/20 | tr=27.5430 va=31.6100 wR2=0.6345 lr=1.00e-03 r2=[0.716, 0.798, 0.315, 0.735, 0.609]\n",
      "effnetv2_s | fold 0 | ep 012/20 | tr=27.7230 va=32.2117 wR2=0.5996 lr=1.00e-03 r2=[0.678, 0.716, 0.335, 0.742, 0.557]\n",
      "effnetv2_s | fold 0 | ep 013/20 | tr=28.3408 va=39.1667 wR2=0.4646 lr=1.00e-03 r2=[0.468, 0.681, 0.193, 0.512, 0.456]\n",
      "effnetv2_s | fold 0 | ep 014/20 | tr=28.8363 va=35.0051 wR2=0.4978 lr=5.00e-04 r2=[0.691, 0.776, -0.039, 0.690, 0.434]\n",
      "effnetv2_s | fold 0 | ep 015/20 | tr=26.2252 va=29.4128 wR2=0.6329 lr=5.00e-04 r2=[0.766, 0.790, 0.388, 0.745, 0.579]\n",
      "effnetv2_s | fold 0 | ep 016/20 | tr=22.9824 va=30.7913 wR2=0.6259 lr=5.00e-04 r2=[0.749, 0.725, 0.383, 0.738, 0.585]\n",
      "Early stop effnetv2_s fold 0 | best wR2=0.6345\n",
      "Done effnetv2_s fold 0 | best wR2=0.6345\n",
      "[init] loaded: tf_efficientnetv2_s_pretrained.safetensors | missing=2 unexpected=0\n",
      "effnetv2_s | fold 1 | ep 000/20 | tr=90.9750 va=72.4587 wR2=-0.5920 lr=1.00e-03 r2=[-0.169, -0.213, -0.160, -0.537, -0.861]\n",
      "effnetv2_s | fold 1 | ep 001/20 | tr=49.8879 va=60.2647 wR2=0.1908 lr=1.00e-03 r2=[0.371, 0.078, -0.016, 0.229, 0.203]\n",
      "effnetv2_s | fold 1 | ep 002/20 | tr=45.4052 va=47.8921 wR2=0.3155 lr=1.00e-03 r2=[0.391, 0.238, 0.120, 0.405, 0.319]\n",
      "effnetv2_s | fold 1 | ep 003/20 | tr=45.2566 va=50.4896 wR2=0.3307 lr=1.00e-03 r2=[0.432, 0.372, -0.009, 0.409, 0.339]\n",
      "effnetv2_s | fold 1 | ep 004/20 | tr=39.9784 va=45.4244 wR2=0.3731 lr=1.00e-03 r2=[0.523, 0.419, 0.304, 0.334, 0.363]\n",
      "effnetv2_s | fold 1 | ep 005/20 | tr=38.3590 va=45.5006 wR2=0.3867 lr=1.00e-03 r2=[0.598, 0.548, 0.231, 0.431, 0.326]\n",
      "effnetv2_s | fold 1 | ep 006/20 | tr=37.7321 va=40.6200 wR2=0.4528 lr=1.00e-03 r2=[0.553, 0.617, 0.390, 0.450, 0.414]\n",
      "effnetv2_s | fold 1 | ep 007/20 | tr=33.6630 va=40.3117 wR2=0.4913 lr=1.00e-03 r2=[0.571, 0.741, 0.281, 0.485, 0.470]\n",
      "effnetv2_s | fold 1 | ep 008/20 | tr=32.9351 va=35.1414 wR2=0.6007 lr=1.00e-03 r2=[0.721, 0.784, 0.380, 0.598, 0.585]\n",
      "effnetv2_s | fold 1 | ep 009/20 | tr=32.2313 va=41.9554 wR2=0.4549 lr=1.00e-03 r2=[0.557, 0.715, 0.099, 0.493, 0.439]\n",
      "effnetv2_s | fold 1 | ep 010/20 | tr=28.3086 va=38.2195 wR2=0.4589 lr=1.00e-03 r2=[0.592, 0.543, 0.393, 0.478, 0.421]\n",
      "effnetv2_s | fold 1 | ep 011/20 | tr=30.6565 va=41.0453 wR2=0.4433 lr=5.00e-04 r2=[0.595, 0.683, 0.413, 0.399, 0.389]\n",
      "effnetv2_s | fold 1 | ep 012/20 | tr=28.6853 va=35.4521 wR2=0.5776 lr=5.00e-04 r2=[0.672, 0.746, 0.480, 0.569, 0.548]\n",
      "effnetv2_s | fold 1 | ep 013/20 | tr=28.1851 va=33.9443 wR2=0.6055 lr=5.00e-04 r2=[0.678, 0.784, 0.496, 0.619, 0.572]\n",
      "effnetv2_s | fold 1 | ep 014/20 | tr=24.1298 va=37.2475 wR2=0.5023 lr=5.00e-04 r2=[0.654, 0.797, 0.463, 0.507, 0.419]\n",
      "effnetv2_s | fold 1 | ep 015/20 | tr=23.0546 va=36.7493 wR2=0.4953 lr=5.00e-04 r2=[0.599, 0.814, 0.413, 0.499, 0.426]\n",
      "effnetv2_s | fold 1 | ep 016/20 | tr=22.4375 va=34.3150 wR2=0.5985 lr=2.50e-04 r2=[0.696, 0.785, 0.394, 0.635, 0.568]\n",
      "effnetv2_s | fold 1 | ep 017/20 | tr=20.8821 va=32.1121 wR2=0.5882 lr=2.50e-04 r2=[0.683, 0.914, 0.395, 0.609, 0.535]\n",
      "effnetv2_s | fold 1 | ep 018/20 | tr=21.6131 va=31.8729 wR2=0.5924 lr=2.50e-04 r2=[0.679, 0.921, 0.344, 0.614, 0.550]\n",
      "Early stop effnetv2_s fold 1 | best wR2=0.6055\n",
      "Done effnetv2_s fold 1 | best wR2=0.6055\n",
      "[init] loaded: tf_efficientnetv2_s_pretrained.safetensors | missing=2 unexpected=0\n",
      "effnetv2_s | fold 2 | ep 000/20 | tr=107.7789 va=74.7861 wR2=-0.5566 lr=1.00e-03 r2=[-0.078, -0.482, -0.366, -0.454, -0.747]\n",
      "effnetv2_s | fold 2 | ep 001/20 | tr=53.9247 va=40.3589 wR2=0.4977 lr=1.00e-03 r2=[0.692, 0.192, -0.181, 0.749, 0.555]\n",
      "effnetv2_s | fold 2 | ep 002/20 | tr=45.4785 va=38.8275 wR2=0.5858 lr=1.00e-03 r2=[0.709, 0.422, 0.142, 0.693, 0.640]\n",
      "effnetv2_s | fold 2 | ep 003/20 | tr=41.1522 va=42.7573 wR2=0.5388 lr=1.00e-03 r2=[0.627, 0.160, 0.091, 0.681, 0.630]\n",
      "effnetv2_s | fold 2 | ep 004/20 | tr=39.4690 va=42.3245 wR2=0.5163 lr=1.00e-03 r2=[0.699, 0.412, 0.177, 0.617, 0.528]\n",
      "effnetv2_s | fold 2 | ep 005/20 | tr=39.2575 va=40.9991 wR2=0.5793 lr=5.00e-04 r2=[0.759, 0.381, -0.065, 0.734, 0.650]\n",
      "effnetv2_s | fold 2 | ep 006/20 | tr=37.0656 va=39.0831 wR2=0.6067 lr=5.00e-04 r2=[0.749, 0.482, 0.041, 0.729, 0.667]\n",
      "effnetv2_s | fold 2 | ep 007/20 | tr=32.1166 va=39.6576 wR2=0.5185 lr=5.00e-04 r2=[0.619, 0.580, 0.078, 0.589, 0.546]\n",
      "effnetv2_s | fold 2 | ep 008/20 | tr=31.6779 va=32.3684 wR2=0.6922 lr=5.00e-04 r2=[0.816, 0.633, 0.020, 0.850, 0.751]\n",
      "effnetv2_s | fold 2 | ep 009/20 | tr=30.2381 va=34.0202 wR2=0.6672 lr=5.00e-04 r2=[0.801, 0.761, 0.030, 0.789, 0.700]\n",
      "effnetv2_s | fold 2 | ep 010/20 | tr=30.4664 va=33.1725 wR2=0.5986 lr=5.00e-04 r2=[0.757, 0.663, 0.178, 0.677, 0.607]\n",
      "effnetv2_s | fold 2 | ep 011/20 | tr=25.6885 va=33.5317 wR2=0.6623 lr=2.50e-04 r2=[0.756, 0.451, 0.096, 0.790, 0.748]\n",
      "effnetv2_s | fold 2 | ep 012/20 | tr=25.8393 va=31.8187 wR2=0.6801 lr=2.50e-04 r2=[0.822, 0.528, 0.199, 0.806, 0.728]\n",
      "effnetv2_s | fold 2 | ep 013/20 | tr=25.3730 va=32.2003 wR2=0.6540 lr=2.50e-04 r2=[0.742, 0.773, 0.171, 0.720, 0.683]\n",
      "Early stop effnetv2_s fold 2 | best wR2=0.6922\n",
      "Done effnetv2_s fold 2 | best wR2=0.6922\n",
      "[init] loaded: tf_efficientnetv2_s_pretrained.safetensors | missing=2 unexpected=0\n",
      "effnetv2_s | fold 3 | ep 000/20 | tr=92.2340 va=62.1194 wR2=-0.1625 lr=1.00e-03 r2=[-0.030, 0.233, -0.196, -0.186, -0.252]\n",
      "effnetv2_s | fold 3 | ep 001/20 | tr=59.2097 va=48.0765 wR2=0.3920 lr=1.00e-03 r2=[0.501, -0.150, 0.187, 0.558, 0.453]\n",
      "effnetv2_s | fold 3 | ep 002/20 | tr=51.4952 va=47.1645 wR2=0.3825 lr=1.00e-03 r2=[0.482, 0.264, 0.350, 0.392, 0.389]\n",
      "effnetv2_s | fold 3 | ep 003/20 | tr=45.7691 va=42.1246 wR2=0.4507 lr=1.00e-03 r2=[0.467, 0.485, 0.419, 0.470, 0.439]\n",
      "effnetv2_s | fold 3 | ep 004/20 | tr=41.9751 va=40.9118 wR2=0.3762 lr=1.00e-03 r2=[0.477, 0.628, 0.288, 0.362, 0.329]\n",
      "effnetv2_s | fold 3 | ep 005/20 | tr=39.1510 va=36.1768 wR2=0.5697 lr=1.00e-03 r2=[0.631, 0.508, 0.330, 0.689, 0.570]\n",
      "effnetv2_s | fold 3 | ep 006/20 | tr=37.9864 va=36.2400 wR2=0.6256 lr=1.00e-03 r2=[0.669, 0.409, 0.434, 0.692, 0.672]\n",
      "effnetv2_s | fold 3 | ep 007/20 | tr=35.7376 va=32.4684 wR2=0.6551 lr=1.00e-03 r2=[0.692, 0.668, 0.327, 0.744, 0.675]\n",
      "effnetv2_s | fold 3 | ep 008/20 | tr=34.0485 va=32.1766 wR2=0.6965 lr=1.00e-03 r2=[0.756, 0.684, 0.413, 0.778, 0.711]\n",
      "effnetv2_s | fold 3 | ep 009/20 | tr=32.2208 va=32.6091 wR2=0.6591 lr=1.00e-03 r2=[0.741, 0.707, 0.376, 0.785, 0.639]\n",
      "effnetv2_s | fold 3 | ep 010/20 | tr=31.7969 va=31.4667 wR2=0.6813 lr=1.00e-03 r2=[0.714, 0.557, 0.577, 0.724, 0.703]\n",
      "effnetv2_s | fold 3 | ep 011/20 | tr=29.7975 va=31.9029 wR2=0.7080 lr=1.00e-03 r2=[0.754, 0.551, 0.343, 0.804, 0.765]\n",
      "effnetv2_s | fold 3 | ep 012/20 | tr=30.8041 va=33.1317 wR2=0.6471 lr=1.00e-03 r2=[0.731, 0.383, 0.388, 0.795, 0.676]\n",
      "effnetv2_s | fold 3 | ep 013/20 | tr=32.0412 va=34.4107 wR2=0.5700 lr=1.00e-03 r2=[0.605, 0.686, 0.427, 0.568, 0.569]\n",
      "effnetv2_s | fold 3 | ep 014/20 | tr=29.4421 va=35.0541 wR2=0.6513 lr=5.00e-04 r2=[0.732, 0.488, 0.381, 0.757, 0.680]\n",
      "effnetv2_s | fold 3 | ep 015/20 | tr=30.9383 va=32.3837 wR2=0.6781 lr=5.00e-04 r2=[0.672, 0.721, 0.562, 0.709, 0.681]\n",
      "effnetv2_s | fold 3 | ep 016/20 | tr=27.8853 va=30.6138 wR2=0.6844 lr=5.00e-04 r2=[0.778, 0.661, 0.466, 0.776, 0.678]\n",
      "Early stop effnetv2_s fold 3 | best wR2=0.7080\n",
      "Done effnetv2_s fold 3 | best wR2=0.7080\n",
      "[init] loaded: tf_efficientnetv2_s_pretrained.safetensors | missing=2 unexpected=0\n",
      "effnetv2_s | fold 4 | ep 000/20 | tr=96.3054 va=70.4570 wR2=-0.6135 lr=1.00e-03 r2=[-0.024, -0.501, -0.485, -0.350, -0.885]\n",
      "effnetv2_s | fold 4 | ep 001/20 | tr=50.5790 va=70.6381 wR2=-0.2400 lr=1.00e-03 r2=[0.494, -2.641, 0.195, -0.332, 0.043]\n",
      "effnetv2_s | fold 4 | ep 002/20 | tr=49.2820 va=61.0022 wR2=0.0126 lr=1.00e-03 r2=[-0.004, -0.172, 0.054, 0.263, -0.056]\n",
      "effnetv2_s | fold 4 | ep 003/20 | tr=43.6999 va=46.7965 wR2=0.4264 lr=1.00e-03 r2=[0.434, 0.239, 0.132, 0.419, 0.524]\n",
      "effnetv2_s | fold 4 | ep 004/20 | tr=41.1028 va=42.0648 wR2=0.4902 lr=1.00e-03 r2=[0.668, 0.152, 0.312, 0.601, 0.513]\n",
      "effnetv2_s | fold 4 | ep 005/20 | tr=40.5838 va=41.0558 wR2=0.3993 lr=1.00e-03 r2=[0.669, 0.141, -0.037, 0.608, 0.401]\n",
      "effnetv2_s | fold 4 | ep 006/20 | tr=36.6493 va=40.1628 wR2=0.5375 lr=1.00e-03 r2=[0.612, 0.451, 0.529, 0.538, 0.541]\n",
      "effnetv2_s | fold 4 | ep 007/20 | tr=32.7779 va=40.3423 wR2=0.4599 lr=1.00e-03 r2=[0.740, -0.811, 0.436, 0.554, 0.625]\n",
      "effnetv2_s | fold 4 | ep 008/20 | tr=32.6031 va=39.6227 wR2=0.4507 lr=1.00e-03 r2=[0.619, 0.200, 0.611, 0.472, 0.427]\n",
      "effnetv2_s | fold 4 | ep 009/20 | tr=31.3229 va=37.4040 wR2=0.5133 lr=5.00e-04 r2=[0.687, 0.391, 0.186, 0.652, 0.513]\n",
      "effnetv2_s | fold 4 | ep 010/20 | tr=33.4264 va=36.7083 wR2=0.5700 lr=5.00e-04 r2=[0.718, -0.013, 0.459, 0.647, 0.648]\n",
      "effnetv2_s | fold 4 | ep 011/20 | tr=28.5727 va=33.9912 wR2=0.6276 lr=5.00e-04 r2=[0.736, 0.264, 0.547, 0.677, 0.675]\n",
      "effnetv2_s | fold 4 | ep 012/20 | tr=26.7251 va=31.8995 wR2=0.5957 lr=5.00e-04 r2=[0.687, 0.306, 0.516, 0.650, 0.629]\n",
      "effnetv2_s | fold 4 | ep 013/20 | tr=23.7614 va=33.5628 wR2=0.5422 lr=5.00e-04 r2=[0.660, 0.313, 0.463, 0.604, 0.555]\n",
      "effnetv2_s | fold 4 | ep 014/20 | tr=24.5903 va=32.9038 wR2=0.5822 lr=2.50e-04 r2=[0.691, 0.325, 0.468, 0.659, 0.604]\n",
      "effnetv2_s | fold 4 | ep 015/20 | tr=23.8204 va=32.7853 wR2=0.5963 lr=2.50e-04 r2=[0.716, 0.396, 0.519, 0.657, 0.604]\n",
      "effnetv2_s | fold 4 | ep 016/20 | tr=21.8067 va=32.2774 wR2=0.5573 lr=2.50e-04 r2=[0.688, 0.286, 0.486, 0.635, 0.569]\n",
      "Early stop effnetv2_s fold 4 | best wR2=0.6276\n",
      "Done effnetv2_s fold 4 | best wR2=0.6276\n",
      "effnetv2_s CV avg: 0.6535513162612915\n",
      "[init] loaded: convnext_base_pretrained.safetensors | missing=4 unexpected=0\n",
      "[init] loaded: convnext_base_pretrained.safetensors | missing=4 unexpected=0\n",
      "[init] loaded: convnext_base_pretrained.safetensors | missing=4 unexpected=0\n",
      "[init] loaded: convnext_base_pretrained.safetensors | missing=4 unexpected=0\n",
      "[init] loaded: convnext_base_pretrained.safetensors | missing=4 unexpected=0\n",
      "[init] loaded: tf_efficientnetv2_s_pretrained.safetensors | missing=2 unexpected=0\n",
      "[init] loaded: tf_efficientnetv2_s_pretrained.safetensors | missing=2 unexpected=0\n",
      "[init] loaded: tf_efficientnetv2_s_pretrained.safetensors | missing=2 unexpected=0\n",
      "[init] loaded: tf_efficientnetv2_s_pretrained.safetensors | missing=2 unexpected=0\n",
      "[init] loaded: tf_efficientnetv2_s_pretrained.safetensors | missing=2 unexpected=0\n",
      "                    sample_id     target\n",
      "0  ID1001187975__Dry_Clover_g   2.355469\n",
      "1    ID1001187975__Dry_Dead_g  25.375000\n",
      "2   ID1001187975__Dry_Green_g  27.671875\n",
      "3   ID1001187975__Dry_Total_g  55.406250\n",
      "4         ID1001187975__GDM_g  30.031250\n",
      "Saved submission.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
      "  has_large_values = (abs_vals > 1e6).any()\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CSIRO Biomass - 0.56-style training recipe\n",
    "# Dual backbone: convnext_base + tf_efficientnetv2_s (local safetensors)\n",
    "# 3 outputs (Green/Clover/Dead) + derived GDM/Total\n",
    "# 20 epochs, KFold, TTA, ensemble\n",
    "# ============================================================\n",
    "\n",
    "TRAIN = True\n",
    "DEBUG = False  # if True: 2 folds, 5 epochs\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import timm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "# ----------------------------\n",
    "# Paths\n",
    "# ----------------------------\n",
    "LOCAL = os.environ.get(\"KAGGLE_KERNEL_RUN_TYPE\", \"\") == \"\"\n",
    "DATA_ROOT = \"../input/\" if LOCAL else \"/kaggle/input/csiro-biomass/\"\n",
    "OUTPUT_DIR = \"./trained_models\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "CONVNEXT_CKPT = \"/kaggle/input/convnext-base-imagenet22k-imagenet1k-weights/pytorch/default/1/convnext_base_pretrained.safetensors\"\n",
    "EFFNETV2_CKPT = \"/kaggle/input/effnetv2/pytorch/default/1/tf_efficientnetv2_s_pretrained.safetensors\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# ----------------------------\n",
    "# Data: train wide (one row per image/sample)\n",
    "# ----------------------------\n",
    "train_df = pd.read_csv(f\"{DATA_ROOT}/train.csv\")\n",
    "train_df[[\"sample_id_prefix\", \"sample_id_suffix\"]] = train_df.sample_id.str.split(\"__\", expand=True)\n",
    "\n",
    "META_COLS = [\"sample_id_prefix\", \"image_path\", \"Sampling_Date\", \"State\", \"Species\", \"Pre_GSHH_NDVI\", \"Height_Ave_cm\"]\n",
    "wide = (\n",
    "    train_df.pivot_table(\n",
    "        index=META_COLS,\n",
    "        columns=\"target_name\",\n",
    "        values=\"target\",\n",
    "        aggfunc=\"first\",\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "REQ = [\"Dry_Green_g\", \"Dry_Clover_g\", \"Dry_Dead_g\"]\n",
    "for c in REQ:\n",
    "    if c not in wide.columns:\n",
    "        wide[c] = 0.0\n",
    "\n",
    "# KFold\n",
    "from sklearn.model_selection import KFold\n",
    "NFOLD = 5\n",
    "kf = KFold(n_splits=NFOLD, shuffle=True, random_state=42)\n",
    "wide[\"fold\"] = -1\n",
    "for f, (_, va_idx) in enumerate(kf.split(wide)):\n",
    "    wide.loc[va_idx, \"fold\"] = f\n",
    "\n",
    "print(\"Train rows:\", len(wide))\n",
    "\n",
    "# ----------------------------\n",
    "# Metric: weighted R2 on 5 targets (3 + derived)\n",
    "# ----------------------------\n",
    "def weighted_r2_score(y_true: np.ndarray, y_pred: np.ndarray):\n",
    "    weights = np.array([0.1, 0.1, 0.1, 0.2, 0.5], dtype=np.float32)\n",
    "    r2s = []\n",
    "    for i in range(5):\n",
    "        yt = y_true[:, i]\n",
    "        yp = y_pred[:, i]\n",
    "        ss_res = np.sum((yt - yp) ** 2)\n",
    "        ss_tot = np.sum((yt - np.mean(yt)) ** 2)\n",
    "        r2 = 1.0 - (ss_res / ss_tot) if ss_tot > 0 else 0.0\n",
    "        r2s.append(r2)\n",
    "    r2s = np.array(r2s, dtype=np.float32)\n",
    "    return float(np.sum(r2s * weights) / np.sum(weights)), r2s\n",
    "\n",
    "def calc_metric(outputs3: np.ndarray, targets3: np.ndarray):\n",
    "    y_true = np.column_stack([\n",
    "        targets3,\n",
    "        targets3[:, 0] + targets3[:, 1],                 # GDM\n",
    "        targets3[:, 0] + targets3[:, 1] + targets3[:, 2]  # Total\n",
    "    ])\n",
    "    y_pred = np.column_stack([\n",
    "        outputs3,\n",
    "        outputs3[:, 0] + outputs3[:, 1],\n",
    "        outputs3[:, 0] + outputs3[:, 1] + outputs3[:, 2]\n",
    "    ])\n",
    "    return weighted_r2_score(y_true, y_pred)\n",
    "\n",
    "# ----------------------------\n",
    "# Loss: same idea as 0.56 notebook\n",
    "# ----------------------------\n",
    "class BiomassLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.base = nn.SmoothL1Loss()\n",
    "\n",
    "    def forward(self, out, y):\n",
    "        lg = self.base(out[:, 0], y[:, 0])\n",
    "        lc = self.base(out[:, 1], y[:, 1])\n",
    "        ld = self.base(out[:, 2], y[:, 2])\n",
    "\n",
    "        pred_gdm = out[:, 0] + out[:, 1]\n",
    "        true_gdm = y[:, 0] + y[:, 1]\n",
    "        l_gdm = self.base(pred_gdm, true_gdm)\n",
    "\n",
    "        pred_total = out.sum(dim=1)\n",
    "        true_total = y.sum(dim=1)\n",
    "        l_total = self.base(pred_total, true_total)\n",
    "\n",
    "        return (1.0*lg + 1.0*lc + 1.0*ld + 0.5*l_gdm + 1.0*l_total)\n",
    "\n",
    "# ----------------------------\n",
    "# Dataset / Dataloader: RESIZE(512,512) like your 0.56 code\n",
    "# ----------------------------\n",
    "def make_transform(img_size=512, aug=True):\n",
    "    if aug:\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomVerticalFlip(p=0.5),\n",
    "            transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.05),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
    "        ])\n",
    "    else:\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
    "        ])\n",
    "\n",
    "class BiomassDataset(Dataset):\n",
    "    def __init__(self, df, img_size=512, aug=True, train=True):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.train = train\n",
    "        self.tfm = make_transform(img_size=img_size, aug=aug)\n",
    "        self.img_size = img_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = Image.open(os.path.join(DATA_ROOT, row[\"image_path\"])).convert(\"RGB\")\n",
    "        img = self.tfm(img)\n",
    "\n",
    "        if self.train:\n",
    "            y = torch.tensor([row[\"Dry_Green_g\"], row[\"Dry_Clover_g\"], row[\"Dry_Dead_g\"]], dtype=torch.float32)\n",
    "            return img, y\n",
    "        else:\n",
    "            return img\n",
    "\n",
    "def make_loader(df, img_size=512, batch_size=8, shuffle=True, aug=True, train=True):\n",
    "    ds = BiomassDataset(df, img_size=img_size, aug=aug, train=train)\n",
    "    return DataLoader(ds, batch_size=batch_size, shuffle=shuffle, num_workers=2, pin_memory=True)\n",
    "\n",
    "# ----------------------------\n",
    "# Safetensors load into timm model\n",
    "# ----------------------------\n",
    "def load_safetensors(path: str):\n",
    "    import safetensors.torch as st\n",
    "    sd = st.load_file(path)\n",
    "    # strip common wrappers if present\n",
    "    if all(k.startswith(\"model.\") for k in sd.keys()):\n",
    "        sd = {k.replace(\"model.\", \"\", 1): v for k,v in sd.items()}\n",
    "    if all(k.startswith(\"module.\") for k in sd.keys()):\n",
    "        sd = {k.replace(\"module.\", \"\", 1): v for k,v in sd.items()}\n",
    "    return sd\n",
    "\n",
    "def strip_head(sd: dict):\n",
    "    drop = (\"head.\", \"fc.\", \"classifier.\")\n",
    "    return {k:v for k,v in sd.items() if not k.startswith(drop)}\n",
    "\n",
    "def init_pretrained(model, ckpt_path):\n",
    "    if not ckpt_path or not Path(ckpt_path).exists():\n",
    "        print(\"[init] ckpt missing:\", ckpt_path)\n",
    "        return\n",
    "    sd = strip_head(load_safetensors(ckpt_path))\n",
    "    missing, unexpected = model.load_state_dict(sd, strict=False)\n",
    "    print(f\"[init] loaded: {Path(ckpt_path).name} | missing={len(missing)} unexpected={len(unexpected)}\")\n",
    "\n",
    "def get_model(model_name, ckpt_path):\n",
    "    m = timm.create_model(model_name, pretrained=False, num_classes=3)\n",
    "    init_pretrained(m, ckpt_path)\n",
    "    return m\n",
    "\n",
    "# ----------------------------\n",
    "# Train / Validate (torch.amp, grad accum)\n",
    "# ----------------------------\n",
    "def train_epoch(model, loader, criterion, optimizer, scaler, accum=4):\n",
    "    model.train()\n",
    "    total = 0.0\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "    for step, (x, y) in enumerate(loader):\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        y = y.to(device, non_blocking=True)\n",
    "\n",
    "        with torch.amp.autocast(device_type=\"cuda\", enabled=(device.type==\"cuda\")):\n",
    "            out = model(x)\n",
    "            loss = criterion(out, y) / accum\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        if (step + 1) % accum == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        total += float(loss.item()) * accum\n",
    "\n",
    "    if len(loader) % accum != 0:\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "    return total / len(loader)\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total = 0.0\n",
    "    outs, trgs = [], []\n",
    "\n",
    "    for x, y in loader:\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        y = y.to(device, non_blocking=True)\n",
    "\n",
    "        with torch.amp.autocast(device_type=\"cuda\", enabled=(device.type==\"cuda\")):\n",
    "            out = model(x)\n",
    "            loss = criterion(out, y)\n",
    "\n",
    "        total += float(loss.item())\n",
    "        outs.append(out.detach().cpu())\n",
    "        trgs.append(y.detach().cpu())\n",
    "\n",
    "    outs = torch.cat(outs).numpy()\n",
    "    trgs = torch.cat(trgs).numpy()\n",
    "    w_r2, r2s = calc_metric(outs, trgs)\n",
    "    return total/len(loader), w_r2, r2s\n",
    "\n",
    "def train_fold(df, fold, model_name, ckpt_path, img_size=512, real_bs=8, accum=4, lr=1e-3,\n",
    "               epochs=20, patience=5, tag=\"model\"):\n",
    "    tr_df = df[df.fold != fold].copy()\n",
    "    va_df = df[df.fold == fold].copy()\n",
    "\n",
    "    tr_loader = make_loader(tr_df, img_size=img_size, batch_size=real_bs, shuffle=True, aug=True, train=True)\n",
    "    va_loader = make_loader(va_df, img_size=img_size, batch_size=real_bs, shuffle=False, aug=False, train=True)\n",
    "\n",
    "    model = get_model(model_name, ckpt_path).to(device)\n",
    "    criterion = BiomassLoss()\n",
    "    optimizer = AdamW(model.parameters(), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"max\", factor=0.5, patience=max(1,patience//2))\n",
    "    scaler = torch.amp.GradScaler(\"cuda\", enabled=(device.type==\"cuda\"))\n",
    "\n",
    "    best = -1e9\n",
    "    bad = 0\n",
    "\n",
    "    for ep in range(epochs):\n",
    "        tr_loss = train_epoch(model, tr_loader, criterion, optimizer, scaler, accum=accum)\n",
    "        va_loss, wR2, r2s = validate(model, va_loader, criterion)\n",
    "        scheduler.step(wR2)\n",
    "\n",
    "        # print EVERY epoch (no confusion)\n",
    "        print(f\"{tag} | fold {fold} | ep {ep:03d}/{epochs} | tr={tr_loss:.4f} va={va_loss:.4f} \"\n",
    "              f\"wR2={wR2:.4f} lr={optimizer.param_groups[0]['lr']:.2e} \"\n",
    "              f\"r2=[{', '.join([f'{x:.3f}' for x in r2s])}]\")\n",
    "\n",
    "        if wR2 > best:\n",
    "            best = wR2\n",
    "            bad = 0\n",
    "            torch.save(model.state_dict(), f\"{OUTPUT_DIR}/{tag}_best_fold{fold}.pth\")\n",
    "        else:\n",
    "            bad += 1\n",
    "\n",
    "        if bad >= patience:\n",
    "            print(f\"Early stop {tag} fold {fold} | best wR2={best:.4f}\")\n",
    "            break\n",
    "\n",
    "    print(f\"Done {tag} fold {fold} | best wR2={best:.4f}\")\n",
    "    return best\n",
    "\n",
    "# ----------------------------\n",
    "# Train both backbones\n",
    "# ----------------------------\n",
    "SPECS = [\n",
    "    {\"tag\":\"convnext_base\", \"name\":\"convnext_base\", \"ckpt\":CONVNEXT_CKPT, \"img\":512, \"bs\":6, \"accum\":4, \"lr\":3e-4},\n",
    "    {\"tag\":\"effnetv2_s\",    \"name\":\"tf_efficientnetv2_s\", \"ckpt\":EFFNETV2_CKPT, \"img\":512, \"bs\":8, \"accum\":4, \"lr\":1e-3},\n",
    "]\n",
    "\n",
    "EPOCHS = 5 if DEBUG else 20\n",
    "RUN_FOLDS = 2 if DEBUG else NFOLD\n",
    "\n",
    "if TRAIN:\n",
    "    for spec in SPECS:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(f\"Training {spec['tag']} | img={spec['img']} | lr={spec['lr']}\")\n",
    "        scores = []\n",
    "        for f in range(RUN_FOLDS):\n",
    "            scores.append(train_fold(\n",
    "                wide, f,\n",
    "                model_name=spec[\"name\"],\n",
    "                ckpt_path=spec[\"ckpt\"],\n",
    "                img_size=spec[\"img\"],\n",
    "                real_bs=spec[\"bs\"],\n",
    "                accum=spec[\"accum\"],\n",
    "                lr=spec[\"lr\"],\n",
    "                epochs=EPOCHS,\n",
    "                patience=5,\n",
    "                tag=spec[\"tag\"]\n",
    "            ))\n",
    "        print(spec[\"tag\"], \"CV avg:\", float(np.mean(scores)))\n",
    "\n",
    "# ----------------------------\n",
    "# Test wide\n",
    "# ----------------------------\n",
    "test_df = pd.read_csv(f\"{DATA_ROOT}/test.csv\")\n",
    "test_df[[\"sample_id_prefix\", \"sample_id_suffix\"]] = test_df.sample_id.str.split(\"__\", expand=True)\n",
    "\n",
    "# One row per image\n",
    "test_wide = test_df[[\"sample_id_prefix\", \"image_path\"]].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# ----------------------------\n",
    "# TTA predict + fold ensemble + backbone ensemble\n",
    "# ----------------------------\n",
    "@torch.no_grad()\n",
    "def predict_tta(model, loader):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    for x in loader:\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        with torch.amp.autocast(device_type=\"cuda\", enabled=(device.type==\"cuda\")):\n",
    "            p1 = model(x)\n",
    "            p2 = model(torch.flip(x, dims=[3]))\n",
    "            p3 = model(torch.flip(x, dims=[2]))\n",
    "            p4 = model(torch.flip(x, dims=[2,3]))\n",
    "            p = (p1+p2+p3+p4)/4.0\n",
    "        preds.append(p.detach().cpu())\n",
    "    p = torch.cat(preds).numpy()\n",
    "    return np.clip(p, 0, None)\n",
    "\n",
    "def predict_backbone(spec):\n",
    "    # loader\n",
    "    ds = BiomassDataset(test_wide, img_size=spec[\"img\"], aug=False, train=False)\n",
    "    loader = DataLoader(ds, batch_size=32, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "    # fold models\n",
    "    fold_files = sorted(Path(OUTPUT_DIR).glob(f\"{spec['tag']}_best_fold*.pth\"))\n",
    "    if len(fold_files) == 0:\n",
    "        raise FileNotFoundError(f\"No fold models found for {spec['tag']} in {OUTPUT_DIR}\")\n",
    "\n",
    "    all_preds = []\n",
    "    for ff in fold_files:\n",
    "        model = get_model(spec[\"name\"], spec[\"ckpt\"]).to(device)\n",
    "        model.load_state_dict(torch.load(ff, map_location=\"cpu\"), strict=True)\n",
    "        all_preds.append(predict_tta(model, loader))\n",
    "\n",
    "    return np.mean(all_preds, axis=0)\n",
    "\n",
    "preds_list = []\n",
    "for spec in SPECS:\n",
    "    preds_list.append(predict_backbone(spec))\n",
    "\n",
    "preds3 = np.mean(preds_list, axis=0)\n",
    "\n",
    "test_wide[\"Dry_Green_g\"]  = preds3[:, 0]\n",
    "test_wide[\"Dry_Clover_g\"] = preds3[:, 1]\n",
    "test_wide[\"Dry_Dead_g\"]   = preds3[:, 2]\n",
    "\n",
    "# PHYSICS CONSISTENCY (CRITICAL)\n",
    "test_wide[\"GDM_g\"]       = test_wide[\"Dry_Green_g\"] + test_wide[\"Dry_Clover_g\"]\n",
    "test_wide[\"Dry_Total_g\"] = test_wide[\"GDM_g\"] + test_wide[\"Dry_Dead_g\"]\n",
    "\n",
    "# submission\n",
    "cols = [\"Dry_Clover_g\",\"Dry_Dead_g\",\"Dry_Green_g\",\"Dry_Total_g\",\"GDM_g\"]\n",
    "sub = test_wide.set_index(\"sample_id_prefix\")[cols].stack().reset_index()\n",
    "sub.columns = [\"sample_id_prefix\",\"target_name\",\"target\"]\n",
    "sub[\"sample_id\"] = sub[\"sample_id_prefix\"] + \"__\" + sub[\"target_name\"]\n",
    "sub = sub[[\"sample_id\",\"target\"]]\n",
    "sub.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "print(sub.head())\n",
    "print(\"Saved submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f40e7d9",
   "metadata": {
    "papermill": {
     "duration": 0.0091,
     "end_time": "2025-12-28T09:46:35.461313",
     "exception": false,
     "start_time": "2025-12-28T09:46:35.452213",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 14254895,
     "isSourceIdPinned": false,
     "sourceId": 112509,
     "sourceType": "competition"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 541787,
     "modelInstanceId": 527730,
     "sourceId": 695833,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 543645,
     "modelInstanceId": 529648,
     "sourceId": 698248,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3764.448344,
   "end_time": "2025-12-28T09:46:38.919666",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-28T08:43:54.471322",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
